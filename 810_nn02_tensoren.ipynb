{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch\n",
    "\n",
    "### Tensoren\n",
    "\n",
    "Tensoren sind eine Verallgemeinerung von Vektoren und Matrizen in höhere Dimensionen\n",
    "\n",
    "Auf die Daten eines Tensors mit Dimension 1 (oder Rang) können wir mit einem Index zugreifen. Wir stellen uns den\n",
    "Tensor als Vektor vor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "shape: torch.Size([3])\n",
      "dim: 1\n",
      "Zugriff auf ein Element: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = [1,2,3]\n",
    "t = torch.tensor(a)\n",
    "print(t)\n",
    "print(\"shape:\", t.shape)\n",
    "print(\"dim:\", t.dim())\n",
    "print(\"Zugriff auf ein Element:\", t[1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension 2\n",
    "\n",
    "Auf die Daten eines Tensors mit Dimension 2 können wir mit 2 Indizes zugreifen. Wir stellen uns den Tensor als Matrix vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "shape: torch.Size([2, 3])\n",
      "dim: 2\n",
      "Zugriff auf ein Element: 6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = [[1,2,3],[4,5,6]]\n",
    "t = torch.tensor(a)\n",
    "print(t)\n",
    "print(\"shape:\", t.shape)\n",
    "print(\"dim:\", t.dim())\n",
    "print(\"Zugriff auf ein Element:\", t[1][2].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension 3\n",
    "\n",
    "Auf die Daten eines Tensors mit Dimension 3 können wir mit 3 Indizes zugreifen. Wir stellen uns den Tensor als Quader (hintereinander gestapelte Matrizen) vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]])\n",
      "shape: torch.Size([2, 2, 3])\n",
      "dim: 3\n",
      "Zugriff auf ein Element: 11\n"
     ]
    }
   ],
   "source": [
    "a = [[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]]\n",
    "t = torch.tensor(a)\n",
    "print(t)\n",
    "print(\"shape:\", t.shape)\n",
    "print(\"dim:\", t.dim())\n",
    "print(\"Zugriff auf ein Element:\", t[1][1][1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf die Daten eines Tensors mit Dimension 4 können wir mit 4 Indizes zugreifen. Wir stellen uns den Tensor als eine Vektor von Quadern vor.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  2,  3],\n",
      "          [ 4,  5,  6]],\n",
      "\n",
      "         [[ 7,  8,  9],\n",
      "          [10, 11, 12]]],\n",
      "\n",
      "\n",
      "        [[[13, 14, 15],\n",
      "          [16, 17, 18]],\n",
      "\n",
      "         [[19, 20, 21],\n",
      "          [22, 23, 24]]]])\n",
      "shape: torch.Size([2, 2, 2, 3])\n",
      "dim: 4\n",
      "Zugriff auf ein Element: 23\n"
     ]
    }
   ],
   "source": [
    "a = [[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]],[[[13,14,15],[16,17,18]],[[19,20,21],[22,23,24]]]\n",
    "t = torch.tensor(a)\n",
    "print(t)\n",
    "print(\"shape:\", t.shape)\n",
    "print(\"dim:\", t.dim())\n",
    "print(\"Zugriff auf ein Element:\", t[1][1][1][1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/nn-tensoren.png\" width=\"600\"/>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape\n",
    "\n",
    "Mit Reshape können wir die Gestalt des Tensors verändern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "        112, 113, 114, 115, 116, 117, 118, 119])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(2*3*4*5))\n",
    "t = torch.tensor(a)    # ein Vektor mit 120 Elementen\n",
    "t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "          56,  57,  58,  59],\n",
       "        [ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
       "          74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "          88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
       "         102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
       "         116, 117, 118, 119]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,60)   # Matrix mit 2 Zeilen, 60 Spalten  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.reshape(60,2)   # Matrix mit 60 Zeilen, 2 Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "           14,  15,  16,  17,  18,  19],\n",
       "         [ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,\n",
       "           34,  35,  36,  37,  38,  39],\n",
       "         [ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
       "           54,  55,  56,  57,  58,  59]],\n",
       "\n",
       "        [[ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,\n",
       "           74,  75,  76,  77,  78,  79],\n",
       "         [ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
       "           94,  95,  96,  97,  98,  99],\n",
       "         [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "          114, 115, 116, 117, 118, 119]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,3,20) # 2 Matrizen mit je 3 Zeilen und 20 Spalten hintereinander gestapelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(117)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,3,20)[1][2][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(93)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,3,4,5)[1][1][2][3]  # 2 Quader, bestehend aus 3 hintereinandergestapelten 4x5 Matrizen  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(88)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,4,3,5)[1][1][2][3] # 2 Quader, bestehend aus 4 hintereinandergestapelten 3x5 Matrizen   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/nn-reshape.png\" width=\"800\"/>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Ein Netz für die OR-Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2,1)\n",
    " \n",
    "    def forward(self, t):\n",
    "        t = self.fc1(t)\n",
    "        t = torch.sigmoid(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1207]],\n",
      "\n",
      "        [[0.9259]],\n",
      "\n",
      "        [[0.9260]],\n",
      "\n",
      "        [[0.9991]]], grad_fn=<SigmoidBackward>)\n",
      "torch.Size([4, 1, 1])\n",
      "[Parameter containing:\n",
      "tensor([[4.5133, 4.5117]], requires_grad=True), Parameter containing:\n",
      "tensor([-1.9862], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([[0,0],[0,1],[1,0],[1,1]]).reshape(4,1,2)\n",
    "Y = torch.Tensor([0,1,1,1]).reshape(4,1,1)\n",
    "\n",
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "for epoch in range(5000):\n",
    "    Y_hat = net(X)\n",
    "    loss = loss_fn(Y_hat, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "            \n",
    "print(net(X))\n",
    "print(net(X).shape)\n",
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/nn-netX.png\" width=\"500\"> \n",
    "\n",
    "### Ein Netz für die XOR-Funktion\n",
    "\n",
    "Bei zwei Neuronen im hidden-Layer kann man schon mal Pech haben. Aber bei drei klappt es meistens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2,3)\n",
    "        self.fc2 = nn.Linear(3,1)\n",
    " \n",
    "    def forward(self, t):\n",
    "        t = self.fc1(t)\n",
    "        t = torch.relu(t)\n",
    "        t = self.fc2(t)\n",
    "        t = torch.sigmoid(t)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0572]],\n",
      "\n",
      "        [[0.9619]],\n",
      "\n",
      "        [[0.9636]],\n",
      "\n",
      "        [[0.0312]]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([[0,0],[0,1],[1,0],[1,1]]).reshape(4,1,2)\n",
    "Y = torch.Tensor([0,1,1,0]).reshape(4,1,1)\n",
    "\n",
    "net = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "for epoch in range(6000):\n",
    "    Y_hat = net(X)\n",
    "    loss = loss_fn(Y_hat, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "            \n",
    "print(net(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
